{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import *\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import GPy\n",
    "\n",
    "l_test_set_path = \"./StarLightCurves/StarLightCurves_TEST\"\n",
    "m_test_set_path = \"./MALLAT/MALLAT_TEST\"\n",
    "\n",
    "# two trained HGP models\n",
    "l_model_class_names = [1,3]\n",
    "m_model_class_names = [3,6]\n",
    "\n",
    "# perc of Testing data used for HGP sample size\n",
    "# do not work \n",
    "l_sample_size_perc = 0.5\n",
    "m_sample_size_perc = 0.5\n",
    "\n",
    "# outlier class names\n",
    "l_outlier_class_names = [2]\n",
    "m_outlier_class_names = [7]\n",
    "\n",
    "# perc of normal and abnormal items\n",
    "# normal_prec + outlier_prec = 1\n",
    "# normal_perc = 0.8\n",
    "outlier_prec = 0.1\n",
    "# total_test_prec = 0.9\n",
    "\n",
    "# top_likelihood_rows_rate = 1.0\n",
    "num_centroids = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Rebbapragada, 2008) mentioned that the shapes of CEPH and RRL are very similar, so they referred to CEPH and RRL as normal classes, and EB was regarded as the anomaly for the known anomalies test. In MALLAT dataset, class 3,6 are normal classes, and class 7,2 are abnormal ones. In this way, they compared the performance of PCAD (their method) with other methods (K-means etc.).\n",
    "\n",
    "- S1: train two HGP models (model 1 uses CEPH and RRL as training dataset; model 2 uses MALLAT class 3,6 as training dataset)\n",
    "- S2: build two testing datasets including 95% normal objectives and 5% outliers for OGLE and MALLAT respectively.\n",
    "- S2: apply model 1 and model 2 to the testing datasets, and measure precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectTopNormalIndex(model_class_names, top_rate):\n",
    "    top_index = []\n",
    "    for m_c in model_class_names:\n",
    "        m_c_index_load = np.loadtxt(\"sorted_result_model-\"+str(m_c)+\"class-\"+str(m_c)+\".csv\", delimiter=',', usecols=[0])\n",
    "        m_c_top_rows_num = int(len(m_c_index_load) * top_rate)\n",
    "        m_c_top_index_list = m_c_index_load[:m_c_top_rows_num:].tolist()\n",
    "        top_index.extend(m_c_top_index_list)\n",
    "    \n",
    "#     print(\"top_index length=\",len(top_index))\n",
    "    return top_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processTestData(test_set_path):\n",
    "    class_names_test = np.loadtxt(test_set_path, delimiter=',', usecols=[0])\n",
    "    test_data = np.loadtxt(test_set_path, delimiter=',', usecols=range(1, 1025))\n",
    "    test_data -= test_data.mean(1)[:,np.newaxis]\n",
    "    test_data /= test_data.std(1)[:,np.newaxis]\n",
    "    \n",
    "    return class_names_test,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_prec doesn't work now\n",
    "def generateTestData(class_test_names, sample_prec, model_class_names, outlier_class_names, normal_index_range=[],total_test_num=600):\n",
    "#     print(outlier_class_names)\n",
    "    if(normal_index_range):\n",
    "        normal_indices = normal_index_range\n",
    "    else:\n",
    "        normal_indices = [i for i,cn in enumerate(class_test_names) if cn in model_class_names]\n",
    "    abnormal_indices = [i for i,cn in enumerate(class_test_names) if cn in outlier_class_names]\n",
    "    \n",
    "#     total_test_indices_num = int(len(normal_indices)*total_test_prec + len(abnormal_indices)*total_test_prec)\n",
    "#     print(\"total_test_indices_num=\",total_test_indices_num)\n",
    "    \n",
    "    \n",
    "# #     print(abnormal_indices)\n",
    "\n",
    "#     normal_num = int(normal_perc * total_test_indices_num)\n",
    "#     abnormal_num = int(outlier_prec * total_test_indices_num)\n",
    "#     print(normal_num,abnormal_num)\n",
    "#     print(len(normal_indices))\n",
    "#     print(len(normal_indices), len(abnormal_indices))\n",
    "\n",
    "    normal_num = int((1-outlier_prec) * total_test_num)\n",
    "    abnormal_num = int(outlier_prec * total_test_num)\n",
    "#     print(normal_num,abnormal_num)\n",
    "    \n",
    "    sample_normal_indices = sample(normal_indices, normal_num)\n",
    "    sample_normal_indices = np.asarray(sample_normal_indices)\n",
    "    sample_normal_indices = sample_normal_indices.reshape(-1,1)\n",
    "    sample_normal_indices = sample_normal_indices.astype(int)\n",
    "    \n",
    "    \n",
    "    sample_abnormal_indices = sample(abnormal_indices, abnormal_num)\n",
    "    sample_abnormal_indices = np.asarray(sample_abnormal_indices)\n",
    "    sample_abnormal_indices = sample_abnormal_indices.reshape(-1,1)\n",
    "    sample_abnormal_indices = sample_abnormal_indices.astype(int)\n",
    "    \n",
    "#     print(sample_normal_indices, sample_abnormal_indices)\n",
    "    \n",
    "    # normal->0; abnormal->1\n",
    "    normal_indicator = np.zeros(len(sample_normal_indices))\n",
    "    normal_indicator = normal_indicator.reshape(-1,1)\n",
    "    \n",
    "    abnormal_indicator = np.ones(len(sample_abnormal_indices))\n",
    "    abnormal_indicator = abnormal_indicator.reshape(-1,1)\n",
    "    \n",
    "#     print(sample_normal_indices.shape, normal_indicator.shape)\n",
    "#     print(sample_abnormal_indices.shape, abnormal_indicator.shape)\n",
    "    normal_array = np.concatenate((sample_normal_indices, normal_indicator), axis=1)\n",
    "#     print(normal_array)\n",
    "    abnormal_array = np.concatenate((sample_abnormal_indices, abnormal_indicator), axis=1)\n",
    "#     print(abnormal_array)\n",
    "    conbine_array = np.concatenate((normal_array, abnormal_array), axis=0)\n",
    "#     print(conbine_array)\n",
    "    \n",
    "    return conbine_array, normal_num, abnormal_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calSumConvergeDis(timeseries_set, cluster, centroids):\n",
    "    sum_r = 0;\n",
    "    for i in range(len(timeseries_set)):\n",
    "        j = int(cluster[i])\n",
    "#         print(j, timeseries_set[i])\n",
    "        corr = np.sum(signal.correlate(timeseries_set[i], centroids[j], mode='same', method='fft')/ len(timeseries_set[i]))\n",
    "        sum_r = sum_r + corr ** 2 * 0.5\n",
    "#     print(sum_r)\n",
    "    return sum_r\n",
    "\n",
    "def calDistance(timeseries_set, centroids):\n",
    "    maxcorr = np.ones(len(timeseries_set)) * -9999\n",
    "    best_centroids = np.ones(len(timeseries_set)) * -1\n",
    "    \n",
    "    for i in range(len(timeseries_set)):\n",
    "        best_center = -1\n",
    "        for j in range(len(centroids)):\n",
    "            corr = np.sum(signal.correlate(timeseries_set[i], centroids[j], mode='same', method='fft')/ len(timeseries_set[i]))\n",
    "            if maxcorr[i] < corr:\n",
    "                maxcorr[i] = corr\n",
    "                best_center = j\n",
    "        best_centroids[i] = best_center\n",
    "    \n",
    "#     print(best_centroids)\n",
    "    return best_centroids\n",
    "\n",
    "def initCentroids(timeseries_set,num_centroids):\n",
    "    random_indexes = sample(list(range(len(timeseries_set))), num_centroids)\n",
    "#     print(\"We initialize the centorids by indexes:\", random_indexes)\n",
    "    \n",
    "#     rand_centroids = np.random.rand(num_centroids,sample_time_index_num)\n",
    "#     print(\"initial_centroids\\n\",rand_centroids)\n",
    "    return timeseries_set[random_indexes]\n",
    "\n",
    "def recalCentroids(timeseries_set, cluster, centroids):\n",
    "    new_centroids = np.array(centroids)\n",
    "    for c in range(len(centroids)):\n",
    "        if len(timeseries_set[cluster==c]) <= 0:\n",
    "            new_centroids[c] = centroids[c];\n",
    "        else:\n",
    "            new_centroids[c] = np.mean(timeseries_set[cluster==c], axis=0)\n",
    "        \n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calLikelihood(test_data, indices, model_class_names, sample_size, method):\n",
    "#     centroids = initCentroids(time_series_set, num_centroids)\n",
    "#     cluster = np.ones(len(time_series_set)) * -1\n",
    "#     E_wc = 0\n",
    "#     converge_iter_up = 20\n",
    "#     up_iteration = 1000\n",
    "#     r = 0\n",
    "\n",
    "#     rand - cc\n",
    "#     cluster = calDistance(time_series_set,centroids)\n",
    "#     print(cluster, centroids)\n",
    "#     while r < converge_iter_up and up_iteration>0:\n",
    "#         cluster = calDistance(time_series_set,centroids)\n",
    "#         centroids = recalCentroids(time_series_set, cluster, centroids)\n",
    "\n",
    "#         E_wc_temp = calSumConvergeDis(time_series_set, cluster, centroids)\n",
    "\n",
    "#         if E_wc_temp > E_wc:\n",
    "# #             print(E_wc_temp)\n",
    "#             r = 0\n",
    "#             E_wc = E_wc_temp\n",
    "\n",
    "#         r = r+1\n",
    "#         up_iteration=up_iteration-1\n",
    "\n",
    "\n",
    "#     print(centroids, \"\\n\",cluster)\n",
    "\n",
    "    indices = [int(i) for i in indices]\n",
    "    time_series_set = test_data[indices]\n",
    "    \n",
    "    if(method == 'spcad'):\n",
    "        file_path_cen = \"./StarLight_files/pcad_save_files/model_save\" + str(model_class_names) + str(sample_size) + \".npy\"\n",
    "        centroids = np.load(file_path_cen);\n",
    "        cluster = calDistance(time_series_set,centroids)\n",
    "    else:\n",
    "        file_path_cen = \"./StarLight_files/pcad_save_files/model_save_r\" + str(model_class_names) + str(sample_size) + \".npy\"\n",
    "        centroids = np.load(file_path_cen);\n",
    "        cluster = calDistance(time_series_set,centroids)\n",
    "    \n",
    "    \n",
    "    score = np.ones(len(indices))\n",
    "    score = score.reshape(-1,1)\n",
    "\n",
    "    n = len(time_series_set)\n",
    "    for index in range(len(time_series_set)):\n",
    "        for j in range(len(centroids)):\n",
    "            c_j_len = len(cluster[cluster==j])\n",
    "            corr = np.sum(signal.correlate(time_series_set[index], centroids[j], mode='same', method='fft')/ len(time_series_set[index]))\n",
    "            score[index] = score[index] + (c_j_len / n) * corr ** 2\n",
    "\n",
    "\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calLikelihood_mallat(test_data, indices, model_class_names, sample_size, method):\n",
    "\n",
    "    indices = [int(i) for i in indices]\n",
    "    time_series_set = test_data[indices]\n",
    "    \n",
    "    if(method == 'spcad'):\n",
    "        file_path_cen = \"./MALLAT_files/pcad_save_files/model_save\" + str(model_class_names) + str(sample_size) + \".npy\"\n",
    "        centroids = np.load(file_path_cen);\n",
    "        cluster = calDistance(time_series_set,centroids)\n",
    "    else:\n",
    "        file_path_cen = \"./MALLAT_files/pcad_save_files/model_save_r\" + str(model_class_names) + str(sample_size) + \".npy\"\n",
    "        centroids = np.load(file_path_cen);\n",
    "        cluster = calDistance(time_series_set,centroids)\n",
    "    \n",
    "    \n",
    "    score = np.ones(len(indices))\n",
    "    score = score.reshape(-1,1)\n",
    "\n",
    "    n = len(time_series_set)\n",
    "    for index in range(len(time_series_set)):\n",
    "        for j in range(len(centroids)):\n",
    "            c_j_len = len(cluster[cluster==j])\n",
    "            corr = np.sum(signal.correlate(time_series_set[index], centroids[j], mode='same', method='fft')/ len(time_series_set[index]))\n",
    "            score[index] = score[index] + (c_j_len / n) * corr ** 2\n",
    "\n",
    "\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted_result_array format\n",
    "\n",
    "| index                               | indicator               | log_predictive_density |\n",
    "|-------------------------------------|-------------------------|:----------------------:|\n",
    "| sampled indexes of  testing dataset | normal(0) / abnormal(1) |                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sortLikelihood(test_array, likelihood):\n",
    "    likelihood = np.asarray(likelihood)\n",
    "    likelihood = likelihood.reshape(-1,1)\n",
    "\n",
    "    combine_result = np.concatenate((test_array, likelihood), axis=1)\n",
    "    sorted_result = np.sort(combine_result.view('f8,f8,f8'), order=['f2'], axis=0).view(np.float)\n",
    "    \n",
    "#     print(sorted_result)\n",
    "    \n",
    "#     result_file_name = \"sorted_result_model.csv\";\n",
    "#     np.savetxt(result_file_name, sorted_result, delimiter=\",\",fmt='%d,%d,%1.9f')\n",
    "    return sorted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calPrecision(sorted_result_array, abnormal_num):\n",
    "    detect_abnormal_num_array = sorted_result_array[0:abnormal_num,:]\n",
    "#     print(detect_abnormal_num_array.shape)\n",
    "    detect_abnormal_num = np.sum(detect_abnormal_num_array[:,1])\n",
    "    return detect_abnormal_num / abnormal_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_array format\n",
    "\n",
    "| index                               | indicator               |\n",
    "|-------------------------------------|-------------------------|\n",
    "| sampled indexes of  testing dataset | normal(0) / abnormal(1) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S2: build testing datasets\n",
    "l_class_names_test, l_test_data = processTestData(l_test_set_path)\n",
    "m_class_names_test, m_test_data = processTestData(m_test_set_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.118\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.134\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.096\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.11\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.102\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.112\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.12\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.116\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.108\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.112\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.106\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.138\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.118\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.11\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.118\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.116\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.108\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.136\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.122\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.114\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.096\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.134\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.112\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.106\n",
      "sample_size= 0.1 method= spcad  total_test_num= 5000  normal_num= 4500  abnormal_num= 500  precision= 0.14\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "top_likelihood_rows_rate = 0.8\n",
    "total_test_num = 5000\n",
    "# method = 'rand-c'\n",
    "method = 'spcad'\n",
    "for i in range(30):\n",
    "    for sample_size in [0.1]:   \n",
    "\n",
    "        # for light-curve data\n",
    "        l_normal_index_range = selectTopNormalIndex(l_model_class_names, top_likelihood_rows_rate)\n",
    "        l_normal_index_range = [int(i) for i in l_normal_index_range]\n",
    "        l_test_array, l_normal_num, l_abnormal_num = generateTestData(l_class_names_test, l_sample_size_perc, l_model_class_names, l_outlier_class_names, l_normal_index_range,total_test_num)\n",
    "\n",
    "        l_likelihood = calLikelihood(l_test_data, l_test_array[:,0],l_model_class_names,sample_size,method)\n",
    "        l_sorted_result_array = sortLikelihood(l_test_array, l_likelihood)\n",
    "        np.savetxt(\"l_sorted_result_array.csv\", l_sorted_result_array, delimiter=\",\",fmt='%d,%d,%1.9f')\n",
    "        l_precision = calPrecision(l_sorted_result_array, l_abnormal_num)\n",
    "        print('sample_size=',sample_size,'method=',method,' total_test_num=',total_test_num,' normal_num=',l_normal_num,' abnormal_num=',l_abnormal_num,' precision=',l_precision)\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size= 0.3 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0166666666667\n",
      "sample_size= 0.4 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0166666666667\n",
      "sample_size= 0.5 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0166666666667\n",
      "sample_size= 0.6 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0166666666667\n",
      "sample_size= 0.7 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0333333333333\n",
      "sample_size= 0.8 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0\n",
      "sample_size= 0.9 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0166666666667\n",
      "sample_size= 1.0 method= rand-c total_test_num= 600  normal_num= 540  abnormal_num= 60  precision= 0.0\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "total_test_num = 600\n",
    "# method = 'spcad'\n",
    "method = 'rand-c'\n",
    "# for i in range(30):\n",
    "for sample_size in [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]:   \n",
    "\n",
    "    # for mallat data\n",
    "    m_test_array, m_normal_num, m_abnormal_num = generateTestData(m_class_names_test, m_sample_size_perc, m_model_class_names, m_outlier_class_names, [], total_test_num)\n",
    "    m_likelihood = calLikelihood_mallat(m_test_data, m_test_array[:,0], m_model_class_names, sample_size, method)\n",
    "    m_sorted_result_array = sortLikelihood(m_test_array, m_likelihood)\n",
    "    np.savetxt(\"m_sorted_result_array.csv\", m_sorted_result_array, delimiter=\",\",fmt='%d,%d,%1.9f')\n",
    "    m_precision = calPrecision(m_sorted_result_array, m_abnormal_num)\n",
    "    print('sample_size=',sample_size,'method=',method,'total_test_num=',total_test_num,' normal_num=',m_normal_num,' abnormal_num=',m_abnormal_num,' precision=',m_precision)\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
